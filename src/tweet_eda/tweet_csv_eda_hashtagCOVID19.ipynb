{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to explore our scraped tweets with query of the hashtag \"#COVID19\". In this we are going to first preprocess the tweets, perform some visualisations and later on investigate if there is a correlation between COVID19 and scarcity and if so, try to quantify it. An issue with this very model is that we require a benchmark to compare against, otherwise the values we report are effectively useless. Maybe a better model would be to query the hashtag \"#Hunger\" or \"#Poverty\" and see how many associations there are with coronavirus. Again, past data would come in handly. Perhaps a Premium Twitter Developer account may help and we can form a partnership of some kind with the right people to aid in this quest for analysis of tweets. More visualiastion here than NLP.\n",
    "\n",
    "\n",
    "Author: Steven Vuong<br>\n",
    "Last Edited: 11-05-2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries we will be using\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_savepath = \"../../data/tweets.csv\"\n",
    "tweets_df = pd.read_csv(csv_savepath) # Of query \"#COVID19\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_creation_date</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>tweet_retweet_count</th>\n",
       "      <th>tweet_favourite_count</th>\n",
       "      <th>tweet_hashtags</th>\n",
       "      <th>user_follow_count</th>\n",
       "      <th>user_created_at</th>\n",
       "      <th>user_verified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-05-11 06:52:34</td>\n",
       "      <td>RT @Parvez_Iftikhar: I tried to tell Sama TV t...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>1180</td>\n",
       "      <td>2015-07-10 10:57:30</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-05-11 06:52:33</td>\n",
       "      <td>All crowd and no social distancing at Paris ga...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>83205</td>\n",
       "      <td>2013-01-04 14:19:42</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-05-11 06:52:33</td>\n",
       "      <td>RT @HackneyAbbott: Muddled messaging from @Bor...</td>\n",
       "      <td>289</td>\n",
       "      <td>0</td>\n",
       "      <td>['coronavirus']</td>\n",
       "      <td>90</td>\n",
       "      <td>2015-09-27 08:00:46</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-05-11 06:52:33</td>\n",
       "      <td>RT @OpenOrphan: We are very pleased to announc...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>266</td>\n",
       "      <td>2016-07-08 16:01:44</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-05-11 06:52:33</td>\n",
       "      <td>For @NicolaSturgeon Alert, adjective meaning \\...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>273</td>\n",
       "      <td>2010-11-03 19:07:27</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweet_creation_date                                         tweet_text  \\\n",
       "0  2020-05-11 06:52:34  RT @Parvez_Iftikhar: I tried to tell Sama TV t...   \n",
       "1  2020-05-11 06:52:33  All crowd and no social distancing at Paris ga...   \n",
       "2  2020-05-11 06:52:33  RT @HackneyAbbott: Muddled messaging from @Bor...   \n",
       "3  2020-05-11 06:52:33  RT @OpenOrphan: We are very pleased to announc...   \n",
       "4  2020-05-11 06:52:33  For @NicolaSturgeon Alert, adjective meaning \\...   \n",
       "\n",
       "   tweet_retweet_count  tweet_favourite_count   tweet_hashtags  \\\n",
       "0                    5                      0               []   \n",
       "1                    0                      0               []   \n",
       "2                  289                      0  ['coronavirus']   \n",
       "3                    1                      0               []   \n",
       "4                    0                      0               []   \n",
       "\n",
       "   user_follow_count      user_created_at  user_verified  \n",
       "0               1180  2015-07-10 10:57:30          False  \n",
       "1              83205  2013-01-04 14:19:42           True  \n",
       "2                 90  2015-09-27 08:00:46          False  \n",
       "3                266  2016-07-08 16:01:44          False  \n",
       "4                273  2010-11-03 19:07:27          False  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will try get some ideas for preprocessing from other notebooks/kernels.\n",
    "\n",
    "-  Idea: Try to predict if tweet contains hashtag \"#Hunger\" or related. Can use tweet text and other data to try and predict then ensemble. Brilliant template for model training: https://www.kaggle.com/abhishek/approaching-almost-any-nlp-problem-on-kaggle\n",
    "-  Preprocessing: https://www.kaggle.com/sudalairajkumar/getting-started-with-text-preprocessing\n",
    "-  Visualisation: https://www.kaggle.com/duttadebadri/detailed-nlp-project-prediction-visualization\n",
    "    - Histogram/barplots for frequency\n",
    "    - Wordcloud (Hoping to do post processing)\n",
    "    - Word correlation map\n",
    "    \n",
    "Also to consider: unigrams/bigrams/trigrams\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/steven/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/steven/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/steven/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "from text_preprocessor import TextPreprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------Sample Text-----------\n",
      "RT @Parvez_Iftikhar: I tried to tell Sama TV that our 4G is badly in need of improvement. Govt needs to give some spectrum plus some tax re…\n",
      "\n",
      "----------Post Processed-----------\n",
      "rt @parveziftikhar try tell sama tv g badly need improvement govt need give spectrum plus tax red\n"
     ]
    }
   ],
   "source": [
    "print(\"-----------Sample Text-----------\")\n",
    "txt_sample = TextPreprocessor(tweets_df[\"tweet_text\"][0])\n",
    "print(txt_sample.text)\n",
    "\n",
    "# Apply preprocessing steps\n",
    "txt_sample._make_lowercase()\n",
    "txt_sample._remove_punctuation()\n",
    "txt_sample._remove_stopwords()\n",
    "txt_sample._lemmatize()\n",
    "txt_sample._remove_emojis()\n",
    "txt_sample._remove_emoticons()\n",
    "txt_sample._remove_urls()\n",
    "txt_sample._remove_html_tags()\n",
    "txt_sample._spellcheck()\n",
    "\n",
    "print(\"\\n----------Post Processed-----------\")\n",
    "print(txt_sample.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing Notes (for this use case):\n",
    "\n",
    "- We opt for lemmatizing in this use case, just that the example output looks better >> Would require more samples to be sure.\n",
    "- We opt for removing emoticons and emojis than converting to words as we want to have a simple model to begin with and conversion may not be so greatly depicted in tweets. May be for other use cases\n",
    "- Keeping slang as it may contain important nuances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Make a plot function -> histogram, worcloud ettc..\n",
    "    # Or does that belong in a separate func? Maybe clas with static\n",
    "    # metthods hauah!\n",
    "# Remove frequent words would have to be performed outside as analysis of \n",
    "# all the words first, then remove. Same applies for removing rare words.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Also considerr stanford NER (named entity recognition) Tagger\n",
    "# https://towardsdatascience.com/tweet-analytics-using-nlp-f83b9f7f7349\n",
    "# from nltk.tag import StanfordNERTagger\n",
    "# from nltk.tokenize import word_tokenize\n",
    "\n",
    "# st = StanfordNERTagger('/stanford-ner/classifiers/english.all.3class.distsim.crf.ser.gz','/usr/share/stanford-ner/stanford-ner.jar',encoding='utf-8')\n",
    "# #a tweet by Donald Trump\n",
    "# text = 'Just had a very good call with @SwedishPM Stefan Löfven who assured me that American citizen A$AP Rocky will be treated fairly. Likewise, I assured him that A$AP was not a flight risk and offered to personally vouch for his bail, or an alternative....'\n",
    "\n",
    "# tokenized_text = word_tokenize(text)\n",
    "# classified_text = st.tag(tokenized_text)\n",
    "\n",
    "# print(classified_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
