{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to explore our scraped tweets with query of the hashtag \"#COVID19\". In this we are going to first preprocess the tweets, perform some visualisations and later on investigate if there is a correlation between COVID19 and scarcity and if so, try to quantify it. An issue with this very model is that we require a benchmark to compare against, otherwise the values we report are effectively useless. Maybe a better model would be to query the hashtag \"#Hunger\" or \"#Poverty\" and see how many associations there are with coronavirus. Again, past data would come in handly. Perhaps a Premium Twitter Developer account may help and we can form a partnership of some kind with the right people to aid in this quest for analysis of tweets. More visualiastion here than NLP.\n",
    "\n",
    "<br>\n",
    "\n",
    "Some time later: Preprocessing took too long, reducing amount of lines to just 1000. Query hashtag \"#hunger\" and see how many are related to '#covid19'. See if we can apply BERT/ALBERT to predict if hashtag also contains #Covid also.\n",
    "\n",
    "\n",
    "Author: Steven Vuong<br>\n",
    "Last Edited: 18-05-2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "csv_savepath = \"../../data/tweets.csv\"\n",
    "tweets_df = pd.read_csv(csv_savepath) # Of query \"#COVID19\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of rows: 1000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_creation_date</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>tweet_retweet_count</th>\n",
       "      <th>tweet_favourite_count</th>\n",
       "      <th>tweet_hashtags</th>\n",
       "      <th>user_follow_count</th>\n",
       "      <th>user_created_at</th>\n",
       "      <th>user_verified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-05-17 14:36:25</td>\n",
       "      <td>RT @jdfarag: The #sun has entered a ‘lockdown’...</td>\n",
       "      <td>111</td>\n",
       "      <td>0</td>\n",
       "      <td>['sun', 'famine', 'endtimes', 'BibleProphecy',...</td>\n",
       "      <td>32</td>\n",
       "      <td>2018-09-17 22:49:14</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-05-17 14:27:49</td>\n",
       "      <td>Kenya's pastoralists face #hunger and conflict...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['hunger', 'Kenya', 'Locusts']</td>\n",
       "      <td>974</td>\n",
       "      <td>2016-06-28 19:39:16</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-05-17 14:21:52</td>\n",
       "      <td>RT @drvandanashiva: #EssentialCommoditiesAct w...</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>['EssentialCommoditiesAct', 'SeedPriceControlO...</td>\n",
       "      <td>27</td>\n",
       "      <td>2010-05-29 12:41:00</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-05-17 14:15:25</td>\n",
       "      <td>But when a man who could literally #hunger in ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['hunger']</td>\n",
       "      <td>836</td>\n",
       "      <td>2009-03-27 01:52:54</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-05-17 14:14:25</td>\n",
       "      <td>RT @PresidentIRL: In April this year, the Pres...</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>['hunger']</td>\n",
       "      <td>375</td>\n",
       "      <td>2014-07-04 16:19:51</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweet_creation_date                                         tweet_text  \\\n",
       "0  2020-05-17 14:36:25  RT @jdfarag: The #sun has entered a ‘lockdown’...   \n",
       "1  2020-05-17 14:27:49  Kenya's pastoralists face #hunger and conflict...   \n",
       "2  2020-05-17 14:21:52  RT @drvandanashiva: #EssentialCommoditiesAct w...   \n",
       "3  2020-05-17 14:15:25  But when a man who could literally #hunger in ...   \n",
       "4  2020-05-17 14:14:25  RT @PresidentIRL: In April this year, the Pres...   \n",
       "\n",
       "   tweet_retweet_count  tweet_favourite_count  \\\n",
       "0                  111                      0   \n",
       "1                    0                      0   \n",
       "2                   36                      0   \n",
       "3                    0                      0   \n",
       "4                    7                      0   \n",
       "\n",
       "                                      tweet_hashtags  user_follow_count  \\\n",
       "0  ['sun', 'famine', 'endtimes', 'BibleProphecy',...                 32   \n",
       "1                     ['hunger', 'Kenya', 'Locusts']                974   \n",
       "2  ['EssentialCommoditiesAct', 'SeedPriceControlO...                 27   \n",
       "3                                         ['hunger']                836   \n",
       "4                                         ['hunger']                375   \n",
       "\n",
       "       user_created_at  user_verified  \n",
       "0  2018-09-17 22:49:14          False  \n",
       "1  2016-06-28 19:39:16          False  \n",
       "2  2010-05-29 12:41:00          False  \n",
       "3  2009-03-27 01:52:54          False  \n",
       "4  2014-07-04 16:19:51          False  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Num of rows: {len(tweets_df)}\")\n",
    "tweets_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will try get some ideas for preprocessing from other notebooks/kernels.\n",
    "\n",
    "-  Idea: Try to predict if tweet contains hashtag \"#Hunger\" or related. Can use tweet text and other data to try and predict then ensemble. Brilliant template for model training: https://www.kaggle.com/abhishek/approaching-almost-any-nlp-problem-on-kaggle\n",
    "-  Preprocessing: https://www.kaggle.com/sudalairajkumar/getting-started-with-text-preprocessing\n",
    "-  Visualisation: https://www.kaggle.com/duttadebadri/detailed-nlp-project-prediction-visualization\n",
    "    - Histogram/barplots for frequency\n",
    "    - Wordcloud (Hoping to do post processing)\n",
    "    - Word correlation map\n",
    "    \n",
    "Also to consider: unigrams/bigrams/trigrams\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/steven/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/steven/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/steven/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "from text_preprocessor import *\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "# Process all tweet texts (really slow) -> Todo: Parallelise\n",
    "processed_tweet_texts = [apply_tweet_text_preprocessing(tweet_text) for tweet_text in tqdm(tweets_df['tweet_text'].values)]\n",
    "\n",
    "# make column for processed tweets and save\n",
    "tweets_df['processed_tweets'] = processed_tweet_texts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df.to_pickle(\"../../data/tweets_processed.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a list of list of all the hashtags (keep order)\n",
    "tweet_hashtags_list = [th.lstrip('[').rstrip(']') for th in tweets_df['tweet_hashtags']]\n",
    "\n",
    "# make a list of all hashtags (altogether)\n",
    "tweet_hashtags = []\n",
    "[tweet_hashtags.extend(thl.split()) for thl in tweet_hashtags_list]\n",
    "\n",
    "# Process all hashtags\n",
    "processed_hashtags = [apply_hashtag_preprocessing(hashtag) for hashtag in tweet_hashtags]\n",
    "\n",
    "print(processed_hashtags[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise counts\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "unique_hashtags, unique_hashtag_counts = np.unique(processed_hashtags, return_counts=True)\n",
    "\n",
    "print(f\"{len(unique_hashtags)} Unique Hashtags\")\n",
    "\n",
    "plot_limit = 20\n",
    "unique_hashtags = [x for _,x in sorted(zip(unique_hashtag_counts,unique_hashtags))][::-1]\n",
    "unique_hashtag_counts = sorted(unique_hashtag_counts)[::-1]\n",
    "\n",
    "unique_hashtags = unique_hashtags[:plot_limit]\n",
    "unique_hashtag_counts = unique_hashtag_counts[:plot_limit]\n",
    "\n",
    "plt.barh(unique_hashtags, unique_hashtag_counts)\n",
    "plt.xticks(rotation=90)\n",
    "plt.xlabel(\"Word Count\")\n",
    "plt.title(f\"Plot of top {plot_limit} occuring words by count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create wordcloud to visualise hashtags\n",
    "# Ref: https://www.geeksforgeeks.org/generating-word-cloud-python/\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "\n",
    "hashtag_string = (\" \").join(processed_hashtags)\n",
    "\n",
    "wordcloud = WordCloud(\n",
    "    width = 800, \n",
    "    height = 800, \n",
    "    background_color ='white', \n",
    "    stopwords = set(STOPWORDS), \n",
    "    min_font_size = 10).generate(hashtag_string) \n",
    "\n",
    "# plot the WordCloud image                        \n",
    "plt.figure(figsize = (8, 8), facecolor = None) \n",
    "plt.imshow(wordcloud) \n",
    "plt.axis(\"off\") \n",
    "plt.tight_layout(pad = 0) \n",
    "  \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the wordcloud above, we see (obviously) 'hunger' is the most dominant word, as it is our query. We want to determine if covid is a related hashtag. So will have to include synonyms and mentions of covid, these include (from above):\n",
    "-  covid19\n",
    "-  coronavirus\n",
    "-  virus\n",
    "-  corona\n",
    "-  covid\n",
    "-  pandemic\n",
    "\n",
    "These other interpretations are what we will deal with, turning this into a supervised learning task. The next step is to create our labels, classsifyng as 1 if 'corona' is mentioned along 'hunger' as hashtags and 0 otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_keyword_in_words(words: List[str], keywords: List[str]) -> bool:\n",
    "    \"\"\"Check if a list of words contain any word in keywords list. Return True \n",
    "    if so, False otherwise.\n",
    "    Args:\n",
    "        - words(List[str])\n",
    "        - keywords(List[str])\n",
    "    Returns:\n",
    "        - True if words contains keyword, False otherwise (bool)\n",
    "    \"\"\"\n",
    "    # replace all empty lists with ['.']\n",
    "    words = [['.'] if not word else word for word in words]\n",
    "\n",
    "    hashtag_bool_list = [True if word in keywords else False for word in words]\n",
    "    return any(hashtag_bool_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process tweets hashtag list\n",
    "processed_tweets_hashtags = [apply_hashtag_preprocessing(hashtag).split() for hashtag in tweet_hashtags_list]\n",
    "\n",
    "# set keywords from what we gathered above\n",
    "covid_related_keywords = ['covid19', 'covid', 'corona', 'virus', 'pandemic', 'coronavirus']\n",
    "\n",
    "# label as 1 if has related covid keyword in list, 0 otherwise\n",
    "contains_keywords = [check_keyword_in_words(pth, covid_related_keywords) for pth in processed_tweets_hashtags]\n",
    "contains_keywords[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise distributions\n",
    "sns.countplot(contains_keywords, palette=\"Set3\")\n",
    "plt.title('Distribution of Tweets from \"#Hunger\" that also contain #COVID19 or related Hashtag')\n",
    "plt.xlabel('Contains Covid Related Keywords')\n",
    "plt.ylabel('Tweet Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add as column to our df -> will use to train NLP Model after more preprocessing\n",
    "tweets_df['covid_hashtag'] = contains_keywords\n",
    "tweets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df.to_pickle(\"../../data/tweets_processed.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Remove most frequent words and most rare words from text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
