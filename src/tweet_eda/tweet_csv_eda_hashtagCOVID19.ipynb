{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to explore our scraped tweets with query of the hashtag \"#COVID19\". In this we are going to first preprocess the tweets, perform some visualisations and later on investigate if there is a correlation between COVID19 and scarcity and if so, try to quantify it. An issue with this very model is that we require a benchmark to compare against, otherwise the values we report are effectively useless. Maybe a better model would be to query the hashtag \"#Hunger\" or \"#Poverty\" and see how many associations there are with coronavirus. Again, past data would come in handly. Perhaps a Premium Twitter Developer account may help and we can form a partnership of some kind with the right people to aid in this quest for analysis of tweets. More visualiastion here than NLP.\n",
    "\n",
    "\n",
    "Author: Steven Vuong<br>\n",
    "Last Edited: 17-05-2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "csv_savepath = \"../../data/tweets.csv\"\n",
    "tweets_df = pd.read_csv(csv_savepath) # Of query \"#COVID19\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_creation_date</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>tweet_retweet_count</th>\n",
       "      <th>tweet_favourite_count</th>\n",
       "      <th>tweet_hashtags</th>\n",
       "      <th>user_follow_count</th>\n",
       "      <th>user_created_at</th>\n",
       "      <th>user_verified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-05-11 06:52:34</td>\n",
       "      <td>RT @Parvez_Iftikhar: I tried to tell Sama TV t...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>1180</td>\n",
       "      <td>2015-07-10 10:57:30</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-05-11 06:52:33</td>\n",
       "      <td>All crowd and no social distancing at Paris ga...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>83205</td>\n",
       "      <td>2013-01-04 14:19:42</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-05-11 06:52:33</td>\n",
       "      <td>RT @HackneyAbbott: Muddled messaging from @Bor...</td>\n",
       "      <td>289</td>\n",
       "      <td>0</td>\n",
       "      <td>['coronavirus']</td>\n",
       "      <td>90</td>\n",
       "      <td>2015-09-27 08:00:46</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-05-11 06:52:33</td>\n",
       "      <td>RT @OpenOrphan: We are very pleased to announc...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>266</td>\n",
       "      <td>2016-07-08 16:01:44</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-05-11 06:52:33</td>\n",
       "      <td>For @NicolaSturgeon Alert, adjective meaning \\...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>273</td>\n",
       "      <td>2010-11-03 19:07:27</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweet_creation_date                                         tweet_text  \\\n",
       "0  2020-05-11 06:52:34  RT @Parvez_Iftikhar: I tried to tell Sama TV t...   \n",
       "1  2020-05-11 06:52:33  All crowd and no social distancing at Paris ga...   \n",
       "2  2020-05-11 06:52:33  RT @HackneyAbbott: Muddled messaging from @Bor...   \n",
       "3  2020-05-11 06:52:33  RT @OpenOrphan: We are very pleased to announc...   \n",
       "4  2020-05-11 06:52:33  For @NicolaSturgeon Alert, adjective meaning \\...   \n",
       "\n",
       "   tweet_retweet_count  tweet_favourite_count   tweet_hashtags  \\\n",
       "0                    5                      0               []   \n",
       "1                    0                      0               []   \n",
       "2                  289                      0  ['coronavirus']   \n",
       "3                    1                      0               []   \n",
       "4                    0                      0               []   \n",
       "\n",
       "   user_follow_count      user_created_at  user_verified  \n",
       "0               1180  2015-07-10 10:57:30          False  \n",
       "1              83205  2013-01-04 14:19:42           True  \n",
       "2                 90  2015-09-27 08:00:46          False  \n",
       "3                266  2016-07-08 16:01:44          False  \n",
       "4                273  2010-11-03 19:07:27          False  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will try get some ideas for preprocessing from other notebooks/kernels.\n",
    "\n",
    "-  Idea: Try to predict if tweet contains hashtag \"#Hunger\" or related. Can use tweet text and other data to try and predict then ensemble. Brilliant template for model training: https://www.kaggle.com/abhishek/approaching-almost-any-nlp-problem-on-kaggle\n",
    "-  Preprocessing: https://www.kaggle.com/sudalairajkumar/getting-started-with-text-preprocessing\n",
    "-  Visualisation: https://www.kaggle.com/duttadebadri/detailed-nlp-project-prediction-visualization\n",
    "    - Histogram/barplots for frequency\n",
    "    - Wordcloud (Hoping to do post processing)\n",
    "    - Word correlation map\n",
    "    \n",
    "Also to consider: unigrams/bigrams/trigrams\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/steven/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/steven/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/steven/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "from text_preprocessor import apply_hashtag_preprocessing, apply_tweet_text_preprocessing\n",
    "from tqdm import tqdm\n",
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process all tweet texts (really slow) -> Todo: Parallelise\n",
    "processed_tweet_texts = [apply_tweet_text_preprocessing(tweet_text) for tweet_text in tqdm(tweets_df['tweet_text'].values)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['coronavirus', 'covid19', 'covid19', 'theatre covid19 lockdown', 'covid19 coronavirusuk']\n"
     ]
    }
   ],
   "source": [
    "# Make a list of all the hashtags\n",
    "tweet_hashtags = [th.lstrip(\"[\").rstrip(\"]\") for th in tweets_df['tweet_hashtags'] if len(th)!=2]\n",
    "\n",
    "# Process all hashtags\n",
    "processed_hashtags = [apply_hashtag_preprocessing(hashtag) for hashtag in tweet_hashtags]\n",
    "\n",
    "print(processed_hashtags[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# Make a plot function -> histogram, worcloud ettc..\n",
    "    # Or does that belong in a separate func? Maybe clas with static methods\n",
    "# Remove frequent words would have to be performed outside as analysis of \n",
    "# all the words first, then remove. Same applies for removing rare words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also could look up #foodbank or #food shortage -> Any text related to food. May take soome manual looking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Remove most frequent words and most rare words from text\n",
    "#Â TODO: Make a loop to process all the words in our dataframe"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
